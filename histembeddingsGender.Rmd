---
title: "Tran_Riddle_Historical Embeddings"
output: 
  html_document:
    toc: true
    toc_float: true
date: December 3, 2024
author: Nela Riddle
---
[Visit the original repository on GitHub](https://github.com/nelariddle/histembeddingsgender)

```{r loadPackages, echo = FALSE, message=FALSE, warning=FALSE}
########################################################

## What are the historical patterns of social group representations?
## 14 social groups, 200 years of Google Books Text

########################################################

## Set up R workspace and packages ----
## Set WD to source file location (python codes, stored data, scripts, etc. can all be shared to one folder for ease of use)
# setwd("**")

# load packages
if (!require("corrplot")) {install.packages("corrplot", dependencies = TRUE);require(corrplot)}
if (!require("reticulate")) {install.packages("reticulate", dependencies = TRUE);require(reticulate)}
if (!require("lsa")) {install.packages("lsa", dependencies = TRUE);require(lsa)}
if (!require("dplyr")) {install.packages("dplyr", dependencies = TRUE);require(dplyr)}
if (!require("devtools")) {install.packages("devtools", dependencies = TRUE);require(devtools)}
# if (!require("sweater")) {devtools::install_github("chainsawriot/sweater");require(sweater)} 
if (!require("sweater")) {install.packages("sweater");require(sweater)} 
if (!require("writexl")) {install.packages("writexl");require(sweater)} 
# contains convenience functions for embeddings analyses 
# see: https://rdrr.io/github/chainsawriot/sweater/f/README.md
```

### Setup
First, load in the pre-written group and word lists to be used in analyses:
```{r loadWords, include=TRUE, warning=FALSE}
## Load in data ----
## Set WD to word stimuli
setwd("wordstim")

# Function to read and process lists
read_list <- function(file, col_name) {
  list_data <- read.delim(file, header = FALSE)
  colnames(list_data) <- col_name
  return(as.vector(list_data[[col_name]]))
}

# Specific groups (men, women)
groupwrds <- read.csv("groupstimlists.csv", header = FALSE)
groupwrds <- as.data.frame(t(groupwrds))
colnames(groupwrds) <- as.character(groupwrds[1, ])
groupwrds <- groupwrds[-1, ]

# Read lists using the function
agentic <- read_list("agentic.txt", "agentic")
communal <- read_list("communal.txt", "communal")
trait <- read_list("traitlist.txt", "trait")
job <- read_list("joblist.txt", "job")
# job <- read_list("joblistDOT.txt", "job")
fruit <- read_list("fruit.txt", "fruit")
noun <- read_list("nouns.txt", "noun")
common <- read_list("common.txt", "common")
```
The agentic and communal lists were borrowed from https://onlinelibrary.wiley.com/doi/10.1002/ejsp.2561; here are some examples
```{r wordExamples}

head(agentic)
head(communal)

```

The group word lists were taken from https://pubmed.ncbi.nlm.nih.gov/35787033/, as well as the trait list:
```{r groupExamples}
head(groupwrds$men)
head(groupwrds$women)
head(trait)
```
The job titles were scraped off this site: https://spotterful.com/blog/job-description-template/job-titles-list-a-z, and expanded through nearest neighbors
```{r jobExamples, echo=FALSE, message=FALSE}
head(job)
```


```{r loadVectors, echo=FALSE, message=FALSE}
# Check unavailable words by decade ----
if (!exists("wordvecs.dat", envir = .GlobalEnv)) {
  load("engall/wordvecsdata_engall.RData", envir = .GlobalEnv)
}
if (!exists("wordvecs.dat_coha", envir = .GlobalEnv)) {
  load("coha/wordvecsdata_coha.RData", envir = .GlobalEnv)
}
unavwords <- lapply(wordvecs.dat, function(x)
  rownames(x)[which(x$V1 == 0)])
n_avwords <- sapply(wordvecs.dat, function(x)
  length(x$V1) - length(rownames(x)[which(x$V1 == 0)]))

unavwords_coha <- lapply(wordvecs.dat_coha, function(x)
  rownames(x)[which(x$V1 == 0)])
n_avwords_coha <- sapply(wordvecs.dat_coha, function(x)
  length(x$V1) - length(rownames(x)[which(x$V1 == 0)])
)
```
### Producing the mac scores
The workhorse function; it iterates over each decade, computing the MAC score between each word and each group, then finds the Pearson correlation of the resulting lists (demonstrated visually later)
```{r importantFunction, message=FALSE}
grpwrdassoc_rel <-
  function(group1index,
           group2index,
           wordterms,
           wordvecs.dat = wordvecs.dat,
           unavwords = unavwords,
           corpus) {
    
    start_year <- if (corpus=="coha") 1820 else 1800
    end_year <- if (corpus=="coha") 2010 else 1990
    
    # Create lists of the group's available words
    availwrds_decade_group1 <-
      lapply(1:length(wordvecs.dat), function(i) {
        groupwrds[, group1index][!groupwrds[, group1index] %in% unavwords[[i]]]
      })
    availwrds_decade_group2 <-
      lapply(1:length(wordvecs.dat), function(i) {
        groupwrds[, group2index][!groupwrds[, group2index] %in% unavwords[[i]]]
      })
    
    
    # Now compute MAC from available words for each decade
    wordvecs.mat <- list()
    mac_group1_2list <- list()
    cor_group1_2 <- list()
    cor_group1_2ts <- vector()
    for (i in 1:length(wordvecs.dat)) {
      wordvecs.mat[[i]] <- as.matrix(wordvecs.dat[[i]])
      mac_group1_2list[[i]] <-
        data.frame(
          grp1ef = mac(wordvecs.mat[[i]], S = wordterms, A = availwrds_decade_group1[[i]])$P,
          grp2ef = mac(wordvecs.mat[[i]], S = wordterms, A = availwrds_decade_group2[[i]])$P,
          trait = names(
            mac(wordvecs.mat[[i]], S = wordterms, A = availwrds_decade_group1[[i]])$P
          )
        )
      cor_group1_2[[i]] <-
        cor.test(mac_group1_2list[[i]]$grp2ef, mac_group1_2list[[i]]$grp1ef)
      cor_group1_2ts[i] <- cor_group1_2[[i]]$estimate
      cor_group1_2ts <-
        ts(
          cor_group1_2ts,
          start = start_year,
          end = end_year,
          frequency = 1 / 10
        )
      print(i)
    }
    output_rel <- list(mac_group1_2list,
                       cor_group1_2ts)
    return(output_rel)
  }
```
An example of how the mac function works (using engall 1990); here we compute the mean average correlation of each word in the first list to the list of animals. It makes sense that the animals in the first list had the highest mac score.
```{r sanityCheck1}
print(mac(
  as.matrix(wordvecs.dat[[20]]),
  S = c("elephant", "horse", "tiger", "happy", "weird", "car"),
  A = c("dog", "cat", "turtle", "fish", "monkey") # the "group" words
)$P)
```
You can compute the cosine similarity of any two words by replacing the lists with single words.
```{r sanityCheck2}
print(mac(
  as.matrix(wordvecs.dat[[20]]),
  S = "happy",
  A = "sad"
)$P)
```

```{r helperFunctions, echo = FALSE, message = FALSE}
overall_results <- data.frame()

generate_data <- function(group1index,
                          group2index,
                          wordterms,
                          corpus) {
  file_path <- paste0("outputs/",
                      paste(group1index, group2index, wordterms, corpus, sep = "_"),
                      ".RData")
  if (file.exists(file_path)) {
    # Load the object from the .RData file into a temporary environment
    temp_env <- new.env()
    load(file_path, envir = temp_env)  # Load the object
    output <- temp_env$output  # Access the loaded object
  } else {
    if (corpus == "coha") {
      wordvecs.dat_selected <- wordvecs.dat_coha
      unavwords_selected <- unavwords_coha
    } else {
      wordvecs.dat_selected <- wordvecs.dat
      unavwords_selected <- unavwords
    }
    output <- grpwrdassoc_rel(
      group1index = group1index,
      group2index = group2index,
      wordterms = get(wordterms),
      wordvecs.dat = wordvecs.dat_selected,
      unavwords = unavwords_selected,
      corpus = corpus
    )
    
    if (!dir.exists("outputs")) {
      dir.create("outputs")
    }
    save(output, file = file_path)
  }
  
  return(output)
}

get_data_internal <- function(group1index,
                              group2index,
                              wordterms,
                              corpus,
                              decade = NULL) {
  # Generate the data
  data <- generate_data(
    group1index = group1index,
    group2index = group2index,
    wordterms = wordterms,
    corpus = corpus
  )
  
  # Select the output based on the `decade`
  if (is.null(decade)) {
    output <- data[[2]]
    
    # Convert the output to a data frame
    years <- time(output)
    values <- as.numeric(output)
    
    new_entry <- data.frame(
      year = years,
      value = values,
      group1index = group1index,
      group2index = group2index,
      wordterms = wordterms,
      corpus = corpus
    )
    
    
    # Check if the combination already exists in the data frame
    existing <- overall_results %>%
      filter(
        group1index == !!group1index,
        group2index == !!group2index,
        wordterms == !!wordterms,
        corpus == !!corpus
      )
    
    # Append to the global results data frame only if the combination is new
    if (nrow(existing) == 0) {
      overall_results <<- bind_rows(overall_results, new_entry)
    }
  } else {
    if (corpus == "coha") {
      output <- data[[1]][[(decade - 1810) / 10]]
    } else {
      output <- data[[1]][[(decade - 1790) / 10]]
    }
    attr(output, "decade") <- decade
  }
  
  # Attach additional attributes
  attr(output, "group1index") <- group1index
  attr(output, "group2index") <- group2index
  attr(output, "wordterms") <- wordterms
  attr(output, "corpus") <- corpus
  
  
  # Return the output regardless
  return(output)
}


get_ts <- function(group1index,
                   group2index,
                   wordterms,
                   corpus) {
  get_data_internal(group1index, group2index, wordterms, corpus)
}

get_decade <-
  function(group1index,
           group2index,
           wordterms,
           corpus,
           decade) {
    get_data_internal(group1index, group2index, wordterms, corpus, decade = decade)
  }

```

```{r sampleCalls, echo = FALSE}
ts1 <- get_ts("men", "women", "agentic", "engall")
ts2 <- get_ts("men", "women", "communal", "coha")
ts3 <- get_ts("men", "women", "noun", "coha")
ts4 <- get_ts("nonhuman", "women", "noun", "coha")



decade1 <- get_decade("men", "women", "agentic", "engall", 1800)
decade2 <- get_decade("men", "women", "agentic", "coha", 1820)
decade2 <- get_decade("men", "women", "noun", "coha", 2010)
```

```{r makePlotsRevised, echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)

plot_one_ts <-
  function(ts_data) {
    ts_df <- data.frame(Year = seq(from = 1800, to = 1990, by = 10),
                        Value = as.vector(ts_data))
    group1 <- attr(ts_data, "group1index")
    group2 <- attr(ts_data, "group2index")
    word_term <- attr(ts_data, "wordterms")
    corpus <- attr(ts_data, "corpus")
    title <-
      paste(group1, "vs", group2, ",", word_term, "(", corpus, ")")
    p <- ggplot(ts_df, aes(x = Year, y = Value)) +
      geom_line(color = "blue") +
      labs(title = title, x = "Year", y = "Value") +
      theme_minimal()
    
    return(p)
  }

plot_multiple_ts <- function(ts_list) {
  combined_df <- data.frame()
  for (i in seq_along(ts_list)) {
    ts_data <- ts_list[[i]]
    ts_df <- data.frame(
      Year = as.vector(time(ts_data)),
      Value = as.vector(ts_data),
      group1 = attr(ts_data, "group1index"),
      group2 = attr(ts_data, "group2index"),
      word_term = attr(ts_data, "wordterms"),
      corpus = attr(ts_data, "corpus")
    )
    combined_df <- rbind(combined_df, ts_df)
  }
  y_min <- min(min(combined_df$Value, na.rm = TRUE), 0)
  y_max <- max(max(combined_df$Value, na.rm = TRUE), 1)
  p <-
    ggplot(combined_df, aes(
      x = Year,
      y = Value,
      color = interaction(group1, group2, word_term)
    )) +
    geom_line() +
    labs(title = "Multiple Time Series Plot, Correlations", x = "Year", y = "Similarity Coefficient") +
    facet_wrap( ~ corpus, scales = "fixed") +
    scale_y_continuous(limits = c(y_min, y_max)) +
    theme_minimal() + guides(color = guide_legend(title = NULL))
  
  return(p)
}

plot_one_decade <- function(decade_data) {
  # Extract attributes
  group1 <- attr(decade_data, "group1index")
  group2 <- attr(decade_data, "group2index")
  word_term <- attr(decade_data, "wordterms")
  corpus <- attr(decade_data, "corpus")
  decade <- attr(decade_data, "decade")
  
  # Calculate Pearson correlation
  pearson_corr <-
    cor(decade_data$grp1ef, decade_data$grp2ef, use = "complete.obs")
  
  # Create title
  title <- paste0(
    group1,
    " vs ",
    group2,
    ", ",
    word_term,
    " (",
    corpus,
    ", ",
    decade,
    ", r = ",
    round(pearson_corr, 2),
    ")"
  )
  
  # Create plot
  p <- ggplot(decade_data, aes(x = grp1ef, y = grp2ef)) +
    geom_point(color = "blue") + geom_smooth(method = "lm", formula = y ~
                                               x) +
    geom_text(aes(label = trait), vjust = -0.5, size = 3) +
    labs(title = title, x = group1, y = group2) +
    theme_minimal()
  
  return(p)
}

```
### Looking at a decade
We can plot the mac scores for two different groups against each other like so:

```{r plottingDecade, warning=FALSE}
plot_one_decade(get_decade("men", "women", "agentic", "coha", 1820))
plot_one_decade(get_decade("men", "women", "agentic", "engall", 1800))
```

The titles of the plots contain the Pearson coefficient, which is what we will use to measure the similarity of the two groups.

### Outlier analysis
Noticing that the 1820 coha plot had an odd correlation, let's check the proportion of gender words that were available, as this could be skewing the slope.
```{r propMissingCoha}
# Calculate the number of missing group words by decade
groupmiss_coha <-
  as.data.frame(sapply(1:dim(groupwrds)[2], function(j) {
    sapply(1:length(wordvecs.dat_coha), function(i) {
      sum(groupwrds[, j] %in% unavwords_coha[[i]])
    })
  }))
colnames(groupmiss_coha) <- colnames(groupwrds)
groupmiss_coha[21,] <- colSums(groupwrds != "", na.rm = TRUE)
groupmiss2_coha <-
  as.data.frame(sapply(1:dim(groupmiss_coha)[2], function(j) {
    1 - groupmiss_coha[1:20, j] / groupmiss_coha[21, j]
  }))
colnames(groupmiss2_coha) <- colnames(groupwrds)

# Add the year column
rownames(groupmiss2_coha) <- seq(1820, 2010, by = 10)
groupmiss2_coha$year <- seq(1820, 2010, by = 10)
groupmiss2_coha
```

```{r plotMissingCoha}
# Create the plot
ggplot(groupmiss2_coha, aes(x = year)) +
  geom_line(aes(y = men, color = "Men")) +
  geom_line(aes(y = women, color = "Women")) +
  scale_color_manual(values = c("Men" = "blue", "Women" = "red")) +
  labs(title = "prop. group words available over time",
       x = "Years",
       y = "Values",
       color = "Legend") +
  theme_minimal()
```
Clearly many fewer words were available in that first decade; let's check for statistical outliers.
```{r outliersMissingCoha}
find_outliers <- function(column, year) {
  is_outlier <-
    abs(column - mean(column, na.rm = TRUE)) > 3 * sd(column, na.rm = TRUE)
  data.frame(Decade = year[is_outlier], Value = column[is_outlier])
}

# Find outliers for men and women
outliers_men <-
  find_outliers(groupmiss2_coha$men, groupmiss2_coha$year)
outliers_women <-
  find_outliers(groupmiss2_coha$women, groupmiss2_coha$year)

# Print results
outliers_men
outliers_women
```
Repeat for engall:
```{r propMissingEngall}
# Calculate the number of missing group words by decade
groupmiss <-
  as.data.frame(sapply(1:dim(groupwrds)[2], function(j) {
    sapply(1:length(wordvecs.dat), function(i) {
      sum(groupwrds[, j] %in% unavwords[[i]])
    })
  }))
colnames(groupmiss) <- colnames(groupwrds)
groupmiss[21,] <- colSums(groupwrds != "", na.rm = TRUE)
groupmiss2 <-
  as.data.frame(sapply(1:dim(groupmiss)[2], function(j) {
    1 - groupmiss[1:20, j] / groupmiss[21, j]
  }))
colnames(groupmiss2) <- colnames(groupwrds)

# Add the year column
rownames(groupmiss2) <- seq(1800, 1990, by = 10)
groupmiss2$year <- seq(1800, 1990, by = 10)
groupmiss2
```

```{r plotMissingEngall}
# Create the plot
ggplot(groupmiss2, aes(x = year)) +
  geom_line(aes(y = men, color = "Men")) +
  geom_line(aes(y = women, color = "Women")) +
  scale_color_manual(values = c("Men" = "blue", "Women" = "red")) +
  labs(title = "prop. group words available over time",
       x = "Years",
       y = "Values",
       color = "Legend") +
  theme_minimal()
```
```{r outliersMissingEngall}
# Find outliers for men and women
outliers_men <-
  find_outliers(groupmiss2$men, groupmiss2_coha$year)
outliers_women <-
  find_outliers(groupmiss2$women, groupmiss2_coha$year)

# Print results
outliers_men
outliers_women
```
Engall has no outliers, as expected.

### Plots, engall

Now we can begin to plot the actual correlation values over time, starting with engall:
```{r plottingTsMenWomen}
men_women_trait_job_ts <-
  list(
    get_ts("men", "women", "trait", "engall"),
    get_ts("men", "women", "job", "engall")
  )
plot_multiple_ts(men_women_trait_job_ts)

men_women_agentic_communal_ts <-
  list(
    get_ts("men", "women", "agentic", "engall"),
    get_ts("men", "women", "communal", "engall")
  )
plot_multiple_ts(men_women_agentic_communal_ts)

```

Now, let's look at the actual magnitudes of the mac scores (rather than the Pearson correlations). To do this, we take the mean of all mac scores with a single group.
```{r meanFunc, echo=FALSE}
overall_results_averages<-data.frame()

get_ts_averages <- function(group1index,
                            wordterms,
                            corpus) {
  if (corpus == "coha") {
    years <- seq(1820, 2010, by = 10)
  } else {
    years <- seq(1800, 1990, by = 10)
  }
  output <- sapply(years, function(year) {
    mean(get_decade(group1index, "women", wordterms, corpus, year)$grp1ef,
         na.rm = TRUE)
  })
  
  output <-
    ts(output,
       start = min(years),
       frequency = 1 / (years[2] - years[1]))
  
  years <- time(output)
  values <- as.numeric(output)
  
  new_entry <- data.frame(
    year = years,
    value = values,
    group1index = group1index,
    wordterms = wordterms,
    corpus = corpus
  )
  
  
  # Check if the combination already exists in the data frame
  existing <- overall_results_averages %>%
    filter(group1index == !!group1index,
           wordterms == !!wordterms,
           corpus == !!corpus)
  
  # Append to the global results data frame only if the combination is new
  if (nrow(existing) == 0) {
    overall_results_averages <<- bind_rows(overall_results_averages, new_entry)
  }
  
  
  attr(output, "group1index") <- group1index
  attr(output, "wordterms") <- wordterms
  attr(output, "corpus") <- corpus
  
  return(output)
}
```

```{r plottingMeans, echo = FALSE}
plot_multiple_ts_averages <- function(ts_list) {
  combined_df <- data.frame()
  for (i in seq_along(ts_list)) {
    ts_data <- ts_list[[i]]
    # print(as.vector(time(ts_data)))
    ts_df <- data.frame(
      Year = as.vector(time(ts_data)),
      Value = as.vector(ts_data),
      group1 = attr(ts_data, "group1index"),
      word_term = attr(ts_data, "wordterms"),
      corpus = attr(ts_data, "corpus")
    )
    combined_df <- rbind(combined_df, ts_df)
  }

  
  y_min <- min(min(combined_df$Value, na.rm = TRUE), -.1)
  y_max <- max(max(combined_df$Value, na.rm = TRUE), .1)
  
  p <-
    ggplot(combined_df, aes(
      x = Year,
      y = Value,
      color = interaction(group1, word_term)
    )) +
    geom_line() +
    labs(title = "Multiple Time Series Plot, Averages", x = "Year", y = "Similarity Coefficient") +
    facet_wrap(~ word_term, scales = "fixed") +
    scale_y_continuous(limits = c(y_min, y_max)) +
    theme_minimal() + guides(color = guide_legend(title = NULL))
  
  return(p)
}
```

```{r plottingTsMenWomenAverages}
men_women_trait_job_ts <-
  list(
    get_ts_averages("men", "agentic", "engall"),
    get_ts_averages("men", "communal", "engall"),
    get_ts_averages("women", "agentic", "engall"),
    get_ts_averages("women", "communal", "engall")
  )
plot_multiple_ts_averages(men_women_trait_job_ts)
```

### Baseline with nonhuman groups

We can also do a baseline test with different groups to see if the men/women correlations are uniquely high.
```{r plottingTsHumanNonhuman}
human_nonhuman_ts <-
  list(
    get_ts("nonhuman", "women", "trait", "coha"),
    get_ts("nonhuman", "men", "trait", "coha"),
    get_ts("nonhuman", "women", "trait", "engall"),
    get_ts("nonhuman", "men", "trait", "engall"),
    get_ts("men", "women", "trait", "engall"),
    get_ts("men", "women", "trait", "coha")
  )
plot_multiple_ts(human_nonhuman_ts)

plot_one_decade(get_decade("nonhuman", "women", "trait", "engall", 1890))

```

### Plots, coha
```{r plottingTsMenWomenCoha}
men_women_trait_job_ts <-
  list(
    get_ts("men", "women", "trait", "coha"),
    get_ts("men", "women", "job", "coha")
  )
plot_multiple_ts(men_women_trait_job_ts)

men_women_agentic_communal_ts <-
  list(
    get_ts("men", "women", "agentic", "coha"),
    get_ts("men", "women", "communal", "coha")
  )
plot_multiple_ts(men_women_agentic_communal_ts)

```

```{r plottingTsMenWomenAveragesCoha}
men_women_trait_job_ts <-
  list(
    get_ts_averages("men", "agentic", "coha"),
    get_ts_averages("men", "communal", "coha"),
    get_ts_averages("women", "agentic", "coha"),
    get_ts_averages("women", "communal", "coha")
  )
plot_multiple_ts_averages(men_women_trait_job_ts)
```

### Data in excel format
Access the files containing all the data, which can be filtered in excel:
```{r overallCSV}
head(overall_results)
write_xlsx(overall_results, "overall_results.xlsx")
```
[overall_results.xlsx](overall_results.xlsx)

```{r overallCSVaverages}
head(overall_results_averages)
write_xlsx(overall_results_averages, "overall_results_averages.xlsx")
```
[overall_results_averages.xlsx](overall_results_averages.xlsx)
